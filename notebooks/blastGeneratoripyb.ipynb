{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "| OPTIMUS BIND | \n",
    "----------------\n",
    "\n",
    "------------------------------------------------------------------------------------------------\n",
    "Version: 0.0.1\n",
    "\n",
    "Last Updated: 17/09/2019\n",
    "\n",
    "Description: Functions which generate a database to plug into the machine learning framework \n",
    "             (Needs to be expanded)\n",
    "\n",
    "Contributors: Sang Young Noh. Jeffrey Brender, Thomas J Card, Mahesh Jethelia, Sahil \n",
    "Contact: sangyoung123@googlemail.com\n",
    "\n",
    "-------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import glob\n",
    "import click\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import re\n",
    "\n",
    "# Subprocess modules for calling on making the \n",
    "\n",
    "import subprocess\n",
    "from subprocess import call\n",
    "\n",
    "# Scipy Stack\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# tqdm\n",
    "\n",
    "import tqdm as tqdm \n",
    "\n",
    "# XML Parser\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "    return tqdm(some_iter)\n",
    "except ModuleNotFoundError:\n",
    "    return some_iter\n",
    "\n",
    "def SKEMPItoPandas(SKEMPI_loc):\n",
    "    '''\n",
    "    Purpose:\n",
    "        1. Loads SKEMPI CSV file.\n",
    "        2. Calculates ddG\n",
    "        3. For multiple measurements, keeps the median value\n",
    "        4. Eliminates entries with mutations on both sides of the interface\n",
    "    Input:\n",
    "        SKEMPI_loc : Location of SKEMPI CSV file\n",
    "    Output:\n",
    "        SKEMPI_df : Pandas dataframe    \n",
    "    '''\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import re\n",
    "\t# fix this\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "    # Constants\n",
    "    R = 1.9872036e-3  # Ideal Gas Constant in kcal\n",
    "\n",
    "    SKEMPI_df = pd.read_csv(SKEMPI_loc, sep=';')\n",
    "\n",
    "    # Convert non numeric temperature comments to numeric values. Default is 298K \n",
    "    ConvertTemp = lambda x: int(re.search(r'\\d+', x).group(0) or 298)\n",
    "    BadTemps = SKEMPI_df.Temperature.str.isnumeric() == 0\n",
    "    SKEMPI_df['Temperature'].loc[BadTemps] = SKEMPI_df['Temperature'].loc[BadTemps].map(ConvertTemp)\n",
    "    SKEMPI_df['Temperature'] = pd.to_numeric(SKEMPI_df['Temperature'], errors='coerce')\n",
    "\n",
    "    # Drop missing values\n",
    "    SKEMPI_df.dropna(subset=['Affinity_wt_parsed'], inplace=True)\n",
    "    SKEMPI_df.dropna(subset=['Affinity_mut_parsed'], inplace=True)\n",
    "\n",
    "    # Calculate free energies\n",
    "    SKEMPI_df['dgWT'] = -R*SKEMPI_df['Temperature']*np.log(SKEMPI_df['Affinity_wt_parsed'])\n",
    "    SKEMPI_df['dgMut'] = -R*SKEMPI_df['Temperature']*np.log(SKEMPI_df['Affinity_mut_parsed'])\n",
    "    SKEMPI_df['ddG'] = SKEMPI_df['dgWT']-SKEMPI_df['dgMut']\n",
    "\n",
    "    # Create a key for unique mutations based on PDB and \n",
    "    SKEMPI_df['MutKey'] = SKEMPI_df['#Pdb']+'_'+SKEMPI_df['Mutation(s)_PDB']\n",
    "    # Replace multiple measurements of the same mutation with the group mean\n",
    "    # May consider grouping by experimental method as well\n",
    "    SKEMPI_df['ddgMedian'] = SKEMPI_df.groupby('MutKey')['ddG'].transform('median')        \n",
    "    SKEMPI_df = SKEMPI_df.drop_duplicates(subset=['MutKey', 'Temperature'], keep='first', inplace=False)\n",
    "\n",
    "    # Flag multiple mutations in the same protein\n",
    "    SKEMPI_df['NumMutations'] = SKEMPI_df['Mutation(s)_PDB'].str.count(',')+1 \n",
    "\n",
    "    # Extract Chains and remove cross chain mutations. Chain is the second position in the mutation code\n",
    "    SKEMPI_df['Prot1Chain'] = SKEMPI_df['#Pdb'].str.split('_').str[1]\n",
    "    SKEMPI_df['Prot2Chain'] = SKEMPI_df['#Pdb'].str.split('_').str[2]\n",
    "    SKEMPI_df['MutSplit'] = SKEMPI_df['Mutation(s)_PDB'].str.split(',')\n",
    "    SKEMPI_df['MutCleanSplit'] = SKEMPI_df['Mutation(s)_cleaned'].str.split(',')\n",
    "\n",
    "\t# SYN added - Added a pdb name column to make it easier to identiy pdb when it comes to implementing\n",
    "\t# mutations\n",
    "\t\n",
    "    NAME = [] \n",
    "    for pdbname in SKEMPI_df['#Pdb']:\n",
    "        name = pdbname.split('_')[0]\n",
    "        NAME.append(name)\n",
    "    SKEMPI_df['NAME'] = NAME\n",
    "\n",
    "    def ChainCheck(df):\n",
    "        if df['NumMutations'] == 1:\n",
    "            CrossChain = False\n",
    "            return CrossChain\n",
    "        else:\n",
    "            Chain = df['MutSplit'][0][1]\n",
    "            if Chain in df['Prot1Chain']:\n",
    "                ChainSet = df['Prot1Chain']\n",
    "            elif Chain in df['Prot2Chain']:\n",
    "                ChainSet = df['Prot2Chain']\n",
    "            for i in range(len(df['MutSplit'])):\n",
    "                Chain = df['MutSplit'][i][1]\n",
    "                if Chain in ChainSet:\n",
    "                    CrossChain = False\n",
    "                else:\n",
    "                    CrossChain = True\n",
    "                    break\n",
    "        return CrossChain\n",
    "\n",
    "    SKEMPI_df['CrossChain'] = SKEMPI_df.apply(ChainCheck, axis=1)\n",
    "    SKEMPI_SingleSided = SKEMPI_df[SKEMPI_df.CrossChain == False]\n",
    "\n",
    "    NumProteins = SKEMPI_SingleSided['#Pdb'].nunique()\n",
    "    NumMutations = SKEMPI_SingleSided['#Pdb'].count()\n",
    "    print(\"There are %s unique single sided mutations in %s proteins\" % (NumMutations, NumProteins))             \n",
    "    return SKEMPI_SingleSided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "Psi-Blast\n",
    "---------\n",
    "\n",
    "Basic Local Alignment Search Tool (BLAST) is a sequence similarity search program\n",
    "used to compare a user's query to a database of sequences.  Given a DNA\n",
    "or amino acid sequence, the BLAST heuristic algorithm finds short matches \n",
    "between two sequences and attempts to start alignments from these \"hot spots\". \n",
    "BLAST also provides statistical information about an alignment such as the \"expectation\"\n",
    "value. Note that BLAST is not a single program, but a family of programs. \n",
    "\n",
    "All BLAST programs search for match between sequences, but there is a specialized \n",
    "BLAST program for each type of sequence search. BLAST is one of the most widely used \n",
    "bioinformatics research tools,  since it has several applications, here is a list of typical \n",
    "BLAST applications.\n",
    "\n",
    "1. Following the discovery of a previously unknown gene in one species, search other genomes \n",
    "   to see if other species carry a similar gene.\n",
    "\n",
    "2. Finding functinoal and evolutionary relationships between sequences\n",
    "\n",
    "3 Search for consensus regulatory patterns such as promoter signals, splicing sites and transcription\n",
    "  factor binding sites\n",
    "\n",
    "4. Infer protein structure based on previously crystallized proteins\n",
    "\n",
    "5. Help identify members of gene families\n",
    "\n",
    "If you work in bioinformatics, chances are that you will need to run some BLAST queries or face the need to process BLAST queries\n",
    "generated by you or by another person. Biopython proves tools for both tasks.\n",
    "\n",
    "----\n",
    "\n",
    "Blast and its variants searches protein and nucleic acid sequences using the BLAST or FASTA method. Both methods \n",
    "find similar protein or nucleic aicd chains inthe PDB. psi-blast is used to find more distantly related seuqences\n",
    "\n",
    "Sequences can be search in two ways\n",
    "\n",
    "- By PDB ID and Chain ID. Type in a PDB in the structure ID text box and select a chain ID from the pull-down menu. This is useful\n",
    "  to find all sequences that are similar to the sequence from the specified chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psiBlastScoring(PATH, PSIBLASTPATHBIN ='/home/oohnohnoh1/Desktop/ACADEMIA/Papermaking/OPTIMUS_BIND/ncbi-blast-2.9.0+/bin/psiblast'):\n",
    "\n",
    "\t\"\"\"\n",
    "\tBiopython has a wrapper for each BLAST executable, so you can run a blast program from inside your \n",
    "\tscript. The wrapper for blastn \n",
    "\t\n",
    "\tNcbiblastnCommandline(blast executable, program name, database, input file, ) .. \n",
    "\n",
    "\tThis function returns a tuple with two file objects. The first one is the actual result \n",
    "\tthe second one is the blast error message.\n",
    "\n",
    "\tThe output is in XML format. This information can be parsed using the tools learned or with \n",
    "\tthe tools provided by Biopython. There is also a way to avoid dealing with the XML \n",
    "\toutput by forcing NCbiblastncommandline to use plain text as output. This is done by using \n",
    "\t\t\n",
    "\t ---------------------------------------------------------------\n",
    "\t| Links for resources I have been looking at to make this code: |\n",
    "\t ---------------------------------------------------------------\n",
    "\n",
    "\t-> https://www.rcsb.org/pages/help/advancedsearch/sequence\n",
    "\n",
    "\t-> https://www.biostars.org/p/10419/\n",
    "\n",
    "\t-> https://biopython.org/DIST/docs/api/Bio.PDB.Polypeptide-module.html\n",
    "\n",
    "\t-> https://www.ncbi.nlm.nih.gov/books/NBK2590/ - Good Psiblast explanation\n",
    "\n",
    "\t--------------------------------------------------------------\n",
    "\n",
    "\t------------------------------\n",
    "\tJB's instructions on psi-blast\n",
    "\t------------------------------\n",
    "\n",
    "\t1. We find all similar interfaces.\n",
    "\t\n",
    "\t2. Make a MSA of structurally aligned sequences (multiple sequence alignment). \n",
    "\n",
    "\t3. Form a score from the probability of a particular mutation showing up in the \n",
    "\t   MSA. \n",
    "\n",
    "\t4. Evaluate the mutation with this score  - This is where we need the mutation.\n",
    "\n",
    "\t---------------------------------------------    \n",
    "\t| What to extract from each PSIBLAST record |\n",
    "\t---------------------------------------------\n",
    "\n",
    "\tInformation required to build the blast tables according to  JB \n",
    "\t\n",
    "\t1. The aligned sequences.\n",
    "\n",
    "\t2. the statistics for the alignment <Statistics set>.\n",
    "\n",
    "\t3. The species name for each.\n",
    "\n",
    "\t4. Hsp_evalue.\n",
    "\n",
    "\tNotes:\n",
    "\t------\n",
    "\n",
    "\t-> Should not require an HPC to run each blast computation\n",
    "\n",
    "\t-> The ialign work is run on the biowulf cluster in the NIH, from what I know\n",
    "\n",
    "\tSome biopython options for blast:\n",
    "\t---------------------------------------------------------\n",
    "\tblastn -> nucleotide vs nucleotide\n",
    "\tblastp -> protein vs protein \n",
    "\tblastx -> translated nucleotide vs protein\n",
    "\ttblastn -> protein vs translcated nucleotide\n",
    "\ttblastx -> translated nucelotide vs translated nucleotide\n",
    "\t---------------------------------------------------------\n",
    "\tParameters\n",
    "\t----------\n",
    "\tPATH: \n",
    "      Path to where the wild type PDBs are found \n",
    "\tPSIBLASTPATH:\n",
    "\t  Path to where the psiblast binary is \n",
    "\t\"\"\"\n",
    "\ttry:\n",
    "\t\tfrom Bio.PDB.PDBIO import PDBIO\n",
    "\t\tfrom Bio.PDB.PDBParser import PDBParser # PDBparser\n",
    "\t\tfrom Bio.Data.IUPACData import protein_letters\n",
    "\t\tfrom Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "\t\tfrom Bio.PDB.Polypeptide import PPBuilder  \n",
    "\t\tfrom Bio.PDB.Polypeptide import standard_aa_names # Standard amino acid names - https://biopython.org/DIST/docs/api/Bio.PDB.Polypeptide-module.html \n",
    "\t\tfrom Bio.PDB.Polypeptide import aa1 #  aa1 = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "\t\tfrom Bio.PDB.Polypeptide import aa3 #  aa3 = ['ALA', 'CYS', 'ASP', 'GLU', 'PHE', 'GLY', 'HIS', 'ILE',... ]\n",
    "\t\tfrom Bio import AlignIO\n",
    "\n",
    "\t\t# ----------------------------------\n",
    "\t\t# | Modules for implementing BLAST |\n",
    "\t\t# ----------------------------------\n",
    "\n",
    "\t\tfrom Bio.Blast.Applications import NcbipsiblastCommandline as psiblastn  # psiblast reader\n",
    "\t\tfrom Bio.Blast import NCBIXML # For reading the BLAST output \n",
    "\n",
    "\t\t# ---------------------------------------------\n",
    "\t\t# | Boilerplate modules to read the sequences |\n",
    "\t\t# ---------------------------------------------\n",
    "\n",
    "\t\tfrom Bio.Seq import Seq\n",
    "\t\tfrom Bio.Seq import translate, transcribe, back_transcribe\n",
    "\t\tfrom Bio.PDB.Polypeptide import PPBuilder\n",
    "\t\tfrom Bio.Alphabet import IUPAC\n",
    "\n",
    "\t\t# ----------------\n",
    "\t\t# | Align module |\n",
    "\t\t# ----------------\n",
    "\t\t\n",
    "\t\tfrom Bio.Align import MultipleSeqAlignment\n",
    "\t\tfrom Bio.SeqRecord import SeqRecord\n",
    "\t\tfrom Bio.Alphabet import generic_protein\n",
    "\n",
    "\t\t# ----------------\n",
    "\t\t# | PANDAS_TABLE |\n",
    "\t\t# ----------------\n",
    "\n",
    "\t\timport pandas as pd\n",
    "\t\tfrom pandas import DataFrame\n",
    "\t\t\n",
    "\t\t# --------\n",
    "\t\t# | TQDM |\n",
    "\t\t# --------\n",
    "\t\t\n",
    "\t\timport tqdm\n",
    "\t\tfrom tqdm import tqdm\n",
    "\t\t\n",
    "\texcept ImportError:\n",
    "\t\tprint (\"Error - cannot imoort BLAST python modules\")\t\n",
    "\t# psiblast executable (bin) \n",
    "\tBLASTEXE = PSIBLASTPATHBIN\n",
    "\tWTArray = []\n",
    "\tnameArray = []\n",
    "\tFoldxPath = \"/home/oohnohnoh1/Desktop/ACADEMIA/Papermaking/OPTIMUS_BIND/FoldX/foldx\"\n",
    "\tTotalDict = {} # Dictionary to store each vlaue \n",
    "\tFULL = [] # List to append to in the end which we will convert into a pandas table \n",
    "\tfor file in tqdm(os.listdir(PATH)): # List the fxout files in the directory, and store them in the array \n",
    "\t\tif file.endswith(\".pdb\"):\n",
    "\t\t\tif file[0] == '.':\n",
    "\t\t\t\tpass\n",
    "\t\t\telse:\n",
    "\t\t\t\tFileLocation = os.path.join(PATH, file)\n",
    "\t\t\t\tWTArray.append(FileLocation) # Array with the appended path and the pdb file\n",
    "\t\t\t\tParser = PDBParser(PERMISSIVE=1)\n",
    "\t\t\t\tstrandName = file.split('.')\n",
    "\t\t\t\tstructure = Parser.get_structure(str(strandName[0]), FileLocation)\n",
    "\t\t\t\tmodel = structure[0] # PDB loader \n",
    "\t\t\t\tppb = PPBuilder()  # PDB builder \n",
    "\t\t\t\thspNumList = [] \n",
    "\t\t\t\tsubprocess.Popen(\"mkdir {}_fasta\".format(strandName[0]), shell = True) # Make a directory to store the fasta files and the xml files\t\t\t\t\n",
    "\t\t\t\t# General top-down explanation for this loop - TODO \n",
    "\t\t\t\t\n",
    "\t\t\t\tfor index, pp in enumerate(ppb.build_peptides(structure)):\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\tsequenceCreator = SeqRecord(Seq(str(pp.get_sequence()), generic_protein), id = str(model.get_list()[index].id))\n",
    "\t\t\t\t\t\talign = MultipleSeqAlignment([sequenceCreator])\n",
    "\t\t\t\t\t\tNAME = \"{}_{}\".format(strandName[0], str(model.get_list()[index].id))\n",
    "\t\t\t\t\t\tAlignIO.write(align,'{}_{}.fasta'.format(strandName[0], str(model.get_list()[index].id)), 'fasta')\n",
    "\t\t\t\t\t\tHsp_statistics = ['Hsp_evalue', 'Hsp_qseq', 'Hsp_hseq'] # xml tabs for Hsp \n",
    "\t\t\t\t\t\tblast_statistics = ['Statistics_db-num', 'Statistics_db-len', 'Statistics_hsp-len', 'Statistics_eff-space', 'Statistics_kappa', 'Statistics_lambda', 'Statistics_entropy'] # xml tabs for statistics\n",
    "\t\t\t\t\t\tsubprocess.Popen(\"mv {}_{}.fasta {}_fasta/.\".format(strandName[0], str(model.get_list()[index].id), strandName[0]), shell = True)\n",
    "\t\t\t\t\t\t# Call psiblast on the generated fasta files\n",
    "\t\t\t\t\t\tpsiblastnCline = psiblastn(cmd = BLASTEXE, query = '{}_fasta/{}_{}.fasta'.format(strandName[0], strandName[0], str(model.get_list()[index].id)), db = \"/home/oohnohnoh1/Desktop/ACADEMIA/Papermaking/OPTIMUS_BIND/PANDAS_TABLE/db/cdd_delta\", evalue = .0005, outfmt=5, out=\"{}_fasta/{}_{}.xml\".format(strandName[0], strandName[0], str(model.get_list()[index].id) ))\n",
    "\n",
    "\t\t\t\t\t\trh,eh = psiblastnCline()\n",
    "\t\t\t\t\t\ttree = ET.parse('{}_fasta/{}_{}.xml'.format(strandName[0], strandName[0], str(model.get_list()[index].id))) # READ XML file\n",
    "\t\t\t\t\t\troot = tree.getroot() # \n",
    "\t\t\t\t\t\tuniqueHIT = 0  # Default index \n",
    "\t\t\t\t\t\tRAND = []\n",
    "\t\t\t\t\t\tTotalDict[NAME] = []\n",
    "\t\t\t\t\t\tfor ind in root.iter(): # Append all hsp_num values \n",
    "\t\t\t\t\t\t\tif ind.tag == 'Hit_num':\n",
    "\t\t\t\t\t\t\t\tuniqueHIT = ind.text\n",
    "\t\t\t\t\t\t\tfor stat in Hsp_statistics:\n",
    "\t\t\t\t\t\t\t\tif ind.tag == stat:\n",
    "\t\t\t\t\t\t\t\t\tRAND.append([strandName[0], uniqueHIT, str(model.get_list()[index].id), ind.tag, ind.text])\n",
    "\t\t\t\t\t\t\tfor stat in blast_statistics:\n",
    "\t\t\t\t\t\t\t\tif ind.tag == stat:\n",
    "\t\t\t\t\t\t\t\t\tRAND.append([strandName[0], uniqueHIT, str(model.get_list()[index].id), ind.tag, ind.text])\n",
    "\t\t\t\t\t\tTotalDict[NAME] = RAND\n",
    "\t\t\t\t\t\t# Get a set of the indices of the HIT and use to loop over each Hsp set of values \n",
    "\t\t\t\t\t\tnumList = [int(row[1]) for row in TotalDict[NAME]]\n",
    "\t\t\t\t\t\tnumList = list(set(numList))\n",
    "\t\t\t\t\t\tnumList.sort()\n",
    "\t\t\t\t\t\tif len(numList) == 0: # I havent made the code to deal with \n",
    "\t\t\t\t\t\t\t#D_1 = [row[4] for row in TotalDict[NAME] if row[3] in blast_statistics]\n",
    "\t\t\t\t\t\t\t#D_1.insert(0, \"{}_{}\".format(strandName[0], str(model.get_list()[index].id)))\n",
    "\t\t\t\t\t\t\t#print (D_1)\n",
    "\t\t\t\t\t\t\t#FULL.append(D_1)\n",
    "\t\t\t\t\t\t\tpass\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tfor hitIndex in numList:\n",
    "\t\t\t\t\t\t\t\tpdRow = []\n",
    "\t\t\t\t\t\t\t\tif hitIndex == 0: # 0 is micelleneous part in the xml file - ignore\n",
    "\t\t\t\t\t\t\t\t\tprint (\"Ignoring the top of the xml output of psiblast...\")\n",
    "\t\t\t\t\t\t\t\t\tpass\n",
    "\t\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\t\tfor row in TotalDict[NAME]:\n",
    "\t\t\t\t\t\t\t\t\t\tif int(row[1]) == hitIndex: # Find the Hsp depending on specific Hit \n",
    "\t\t\t\t\t\t\t\t\t\t\tfor stat in Hsp_statistics:\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tif row[3] == stat: # If the xml matches the Hsp statistics tags, we append\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tpdRow.append(row[4])\n",
    "\t\t\t\t\t\t\t\t\t\t\tfor stat in blast_statistics:\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tif row[3] == stat: # If the xml matches the Hsp statistics tags, we append\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tpdRow.append(row[4])\n",
    "\t\t\t\t\t\t\t\t\t\t\t#print(int(row[1]), hitIndex, row)\n",
    "\t\t\t\t\t\t\t\tpdRow.insert(0,hitIndex)\n",
    "\t\t\t\t\t\t\t\tpdRow.insert(0, \"{}_{}\".format(strandName[0], str(model.get_list()[index].id)))\n",
    "\t\t\t\t\t\t\t\tif len(pdRow) == 12: # There is an issue that some have multiple hits.. so will\t\t\t\t\t\t\t\t\t              # have more then 5 for the length, so need to take that into account \n",
    "\t\t\t\t\t\t\t\t\tFULL.append(pdRow)\n",
    "\t\t\t\t\texcept IndexError:\n",
    "\t\t\t\t\t\tprint (\"Error for {}!\".format(file))\n",
    "\tsubprocess.Popen(\"rm -r *_fasta\", shell = True) # Remove all the files that was formed in the psiblast analysis\n",
    "\tdf = pd.DataFrame(FULL, columns = ['PDB_res', 'Index', 'Hsp_evalue', 'Hsp_qseq', 'Hsp_hseq','Statistics_db-num', 'Statistics_db-len', 'Statistics_hsp-len', 'Statistics_eff-space', 'Statistics_kappa', 'Statistics_lambda', 'Statistics_entropy'])  # Column names for the pandas table\n",
    "\tdf.to_csv(\"psiblastData.csv\", sep = ',')\n",
    "\treturn df"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
